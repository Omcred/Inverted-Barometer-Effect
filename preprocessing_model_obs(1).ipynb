{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0a5fb8-eef4-4bc8-81c6-5f23c192ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nbhome/ogrp/python/envs/py311_20241018/lib/python3.11/site-packages/utide/harmonics.py:16: RuntimeWarning: invalid value encountered in cast\n",
      "  nshallow = np.ma.masked_invalid(const.nshallow).astype(int)\n",
      "/nbhome/ogrp/python/envs/py311_20241018/lib/python3.11/site-packages/utide/harmonics.py:17: RuntimeWarning: invalid value encountered in cast\n",
      "  ishallow = np.ma.masked_invalid(const.ishallow).astype(int) - 1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import utide\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62608478-bd91-47c6-b54d-044b8b16461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start=1958\n",
    "year_end=2014\n",
    "\n",
    "model_loc = ['SEATTLE', 'SANDY_HOOK', 'WELLINGTON_HARBOUR']\n",
    "\n",
    "gesla_loc = {'SEATTLE': \"seattle-9447130-usa-noaa\",\n",
    "\t\t  'SANDY_HOOK': \"sandy_hook-8531680-usa-noaa\",\n",
    "          'WELLINGTON_HARBOUR': \"wellington-071a-nzl-uhslc\"}\n",
    "\n",
    "ds = xr.open_dataset(\"/vftmp/Olivia.Mcredmond/data/model_timeseries_odiv181.nc\",decode_times=True)\n",
    "da = xr.open_dataset(\"/vftmp/Olivia.Mcredmond/data/model_timeseries_odiv2.nc\",decode_times=True)\n",
    "odiv181_pressure= xr.open_dataset(\"/vftmp/Olivia.Mcredmond/data/model_timeseries_psl_odiv181.nc\")\n",
    "odiv2_pressure= xr.open_dataset(\"/vftmp/Olivia.Mcredmond/data/model_timeseries_psl_odiv2.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df470b79-0932-4867-bea4-803c1db43840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_data(location_name, year_start,year_end):\n",
    "    model_ts = ds[location_name]\n",
    "    model_ta = da[location_name]\n",
    "    \n",
    "    model2= model_ta.sel(time=slice(f\"{year_start}-01-01\", f\"{year_end}-12-31\"))\n",
    "    model2= model2-model2.mean()\n",
    "    model2['time']=[pd.to_datetime(str(np.array(model2.time[i])), format='mixed', yearfirst=True) for i in range(0,len(np.array(model2)))]\n",
    "    \n",
    "    model181= model_ts.sel(time=slice(f\"{year_start}-01-01\", f\"{year_end}-12-31\"))\n",
    "    model181=model181-model181.mean()\n",
    "    model181['time']=[pd.to_datetime(str(np.array(model181.time[i])), format='mixed', yearfirst=True) for i in range(0,len(np.array(model181)))]\n",
    "    \n",
    "    model2_IB = -1*(odiv2_pressure[location_name].sel(time=slice(f\"{year_start}-01-01\", f\"{year_end}-12-31\")))*0.01*0.1/(1.02*9.8)\n",
    "    model2_IB['time']=[pd.to_datetime(str(np.array(model2_IB.time[i])), format='mixed', yearfirst=True) for i in range(0,len(np.array(model2_IB)))]\n",
    "    model2_IB = model2+(model2_IB-model2_IB.mean())\n",
    "    \n",
    "    model181_IB=-1*(odiv181_pressure[location_name].sel(time=slice(f\"{year_start}-01-01\", f\"{year_end}-12-31\")))*0.01*0.1/(1.02*9.8)\n",
    "    model181_IB['time']=[pd.to_datetime(str(np.array(model181_IB.time[i])), format='mixed', yearfirst=True) for i in range(0,len(np.array(model181_IB)))]\n",
    "    model181_IB = model181+np.array(model181_IB-model181_IB.mean())\n",
    "    \n",
    "    model_output=xr.Dataset(\n",
    "        data_vars={\"model_181\":model181,\n",
    "                   \"model_2\":model2,\n",
    "                   \"model_2_IB\":model2_IB,\n",
    "                   \"model_181_IB\":model181_IB},\n",
    "        coords={\"time\":model2.time},\n",
    "        attrs={'location_name':str({location_name})})\n",
    "    return model_output\n",
    "\t\t## this will save ST_PETERSBURG_MODEL_PROCESSED.nc as a\n",
    "## file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5322d7b3-f9dc-4814-aab6-d61305e3ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gesla_data(location_name, year_start, year_end):\n",
    "    gesla_name = gesla_loc[location_name]\n",
    "    data = f'../data/{gesla_name}'\n",
    "    with open(data) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for row in lines:\n",
    "        word = 'LATITUDE'\n",
    "        if row.find(word) != -1:\n",
    "            lat= float((row.split(\"DE \")[1]).strip())\n",
    "            break\n",
    "    for row in lines:\n",
    "        word = 'LONGITUDE'\n",
    "        if row.find(word) != -1:\n",
    "            long= float((row.split(\"DE \")[1]).strip())\n",
    "            break\n",
    "    names = [\"date\", \"hour\", \"sealevel\", \"flag\", \"use_flag\"]\n",
    "    #Read data from file\n",
    "    obs = pd.read_csv(\n",
    "        data,\n",
    "        names=names,\n",
    "        skiprows=41, # to skip the large header and documentation, would need to check whether this is the same for every time series\n",
    "        skipinitialspace=True,\n",
    "        delim_whitespace=True,\n",
    "        na_values=\"-99.9999\",\n",
    "    )\n",
    "    \n",
    "    #Turn bad data to nan using flags\n",
    "    good_data = obs['use_flag'] == 1\n",
    "    bad_data = obs['use_flag'] == 0\n",
    "    obs.loc[bad_data, \"sealevel\"] = np.nan\n",
    "    \n",
    "    #Subtract mean and define datetime\n",
    "    obs[\"anomaly\"] = obs['sealevel'] - obs['sealevel'].mean()\n",
    "    obs['datetime'] = pd.to_datetime(obs['date'] + ' ' +obs['hour'])\n",
    "    \n",
    "    t1 = (obs['datetime'] >= f'{year_start}-1-1') & (obs['datetime'] <= f'{year_end}-12-31')\n",
    "    obs_t1=obs.loc[t1]\n",
    "    print(\"pt 1\")\n",
    "    coef = utide.solve(\n",
    "        obs_t1.datetime,\n",
    "        obs_t1.anomaly,\n",
    "        lat= lat,\n",
    "        method=\"ols\",\n",
    "        conf_int=\"MC\",\n",
    "        verbose=False,\n",
    "       constit=['M2', 'K1', 'O1', 'S2', 'P1', 'N2', 'K2'] \n",
    "    )\n",
    "    tide = utide.reconstruct(obs_t1.datetime, coef, verbose=False)\n",
    "    obs_t1['sealevel_tr'] = obs_t1.anomaly - tide.h\n",
    "    obs_t1['datetime'] = pd.to_datetime(obs_t1['datetime'])\n",
    "    # Set the datetime column as the index\n",
    "    obs_t1.set_index('datetime', inplace=True)\n",
    "    # Resample from hourly to daily and calculate the daily average\n",
    "    daily_avg=obs_t1['sealevel_tr'].resample('D').mean()\n",
    "    daily_avg=daily_avg.to_frame()\n",
    "    daily_set = xr.Dataset.from_dataframe(daily_avg)\n",
    "    daily_set.attrs['location_name']=location_name\n",
    "    daily_set.attrs['latitude']=lat\n",
    "    daily_set.attrs['longitude']=long\n",
    "    return daily_set\n",
    "## You can then compare ST_PETERSBURG_MODEL_PROCESSED.nc and ST_PETERSBURG_GESLA_PROCESSED.nc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c72b329-d0cd-47d5-9ef4-8fdf56da93ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:19: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  obs = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_t1['sealevel_tr'] = obs_t1.anomaly - tide.h\n",
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_t1['datetime'] = pd.to_datetime(obs_t1['datetime'])\n",
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:19: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  obs = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_t1['sealevel_tr'] = obs_t1.anomaly - tide.h\n",
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_t1['datetime'] = pd.to_datetime(obs_t1['datetime'])\n",
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:19: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  obs = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_t1['sealevel_tr'] = obs_t1.anomaly - tide.h\n",
      "/vftmp/Olivia.Mcredmond/pid155867/ipykernel_156739/1960289138.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_t1['datetime'] = pd.to_datetime(obs_t1['datetime'])\n"
     ]
    }
   ],
   "source": [
    "for i in model_loc:\n",
    "    model_output=process_model_data(i,year_start,year_end)\n",
    "    obs=process_gesla_data(i,year_start,year_end)\n",
    "    Location_dataset=xr.Dataset(\n",
    "        data_vars={\"model_181\":model_output.model_181,\n",
    "                   \"model_2\":model_output.model_2,\n",
    "                   \"model_2_IB\":model_output.model_2_IB,\n",
    "                   \"model_181_IB\":model_output.model_181_IB,\n",
    "                   \"obs\":obs.sealevel_tr},\n",
    "        coords={\"time\":model_output.time},\n",
    "        attrs={'location_name':model_output.location_name,\n",
    "               'latitude': obs.latitude,\n",
    "               'longitude':obs.longitude})\n",
    "    Location_dataset.to_netcdf(f'/vftmp/Olivia.Mcredmond/data/cdf files/{i}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50441083-2ffd-45f6-bf7c-a1b7cb9b4681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
